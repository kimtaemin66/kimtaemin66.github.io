---
layout: post
title: 2022 DACON SW중심대학 공동 AI 경진대회 예선
date: 2022-09-01 14:30:23 +0900
category: Activity
---
**2022 DACON 공동 AI 경진대회 예선 2022.08.01 ~ 2022.08.26**  
**심리성향 예측, nerdiness 값 예측**  
&nbsp;  
train 데이터 셋
![train.csv](/images/traincsv.jpg)  
&nbsp;  
LGBM 활용 코드  
```ruby
import numpy as np
import pandas as pd
from lightgbm import LGBMClassifier
import warnings
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

warnings.filterwarnings('ignore')

##데이터 불러오기
train_df = pd.read_csv('C:/Users/HP/Desktop/competition_data/train.csv')
"""train_aug_df = pd.read_csv('C:/Users/HP/Desktop/competition_data/train_new.csv')
test_df = pd.read_csv('C:/Users/HP/Desktop/competition_data/test.csv')
train_df = pd.concat([train_df, train_aug_df])"""

##필요없는 COLUMN 삭제
train_df = train_df.drop(['index'], axis = 1)
"""test_df = test_df.drop(['index', 'country'], axis = 1)"""

label_encoder = LabelEncoder()
train_df['country'] = label_encoder.fit_transform(train_df['country'])

##결측치 대치
##train_df.interpolate(method = 'linear', inplace = True)
train_df.mode()

##데이터 정보 출력
##train_df = train_df.astype('int')
train_df.head()
train_df.info()

train_df.to_csv("submissiondata.csv",index = False)

##train을 target과 feature로 나누기
feature=train_df.drop(['nerdiness'], axis=1)
target=train_df['nerdiness']
"""X_train=train_df.drop(['nerdiness'], axis=1)
Y_train=train_df['nerdiness']"""

##train_df를 훈련 셋과 테스트 셋으로 나누기
X_train,X_test,Y_train,Y_test = train_test_split(feature,target, test_size=0.2, random_state=55)

##하이퍼 파라미터
"""lgbm_clf = LGBMClassifier(
            n_estimators=1000, 
            num_leaves=50, 
            subsample=0.8, 
            min_child_samples=600, 
            max_depth=200
        )"""

lgbm_clf = LGBMClassifier(n_estimators=1000)

##모델 학습
lgbm_clf.fit(X_train, Y_train)
"""lgbm_clf.fit(X_train, Y_train)"""

##예측 실행
lgbm_pred = lgbm_clf.predict(X_test)


# 제출 파일 생성
"""submission = pd.read_csv('C:/Users/HP/Desktop/competition_data/sample_submission.csv')
submission
submission['nerdiness'] = lgbm_pred
submission
submission.to_csv("baseline.csv", index = False)"""

print("정확도 : {0: .4f}".format(accuracy_score(Y_test,lgbm_pred)))
```
&nbsp;  
LGBM을 활용하여 모델을 개발했을 때 정확도는 82% 였다.  
대회에서 제공한 baseline code를 활용한 모델의 정확도는 80%였다.  
눈에 띄는 정확도의 상승이 없었기 때문에 train.csv 내의 속성의 개수를 늘리거나  
중요도가 낮은, 비어있는 값이 포함되어있는 속성을 지우거나 결측치 대치,  
하이퍼파라미터 조정 등 여러 방면으로 시도해보았으나 눈에 띄는 상승은 없었다.  
예선 대회 종료 직전 nerdiness 값이 0과 1이 아닌 소수점 단위의 확률로  
나와야 한다는 것을 깨닫게 되었다. 0(아니다)과 1(그렇다)의 이분법적인 사고가  
아닌 0에 가까운 값, 1에 가까운 값 등 확률로 나와야 한다는 것을 늦게 깨닫게 돼서  
굉장히 아쉬움이 컸던 대회였다.  


